#!/usr/bin/env python3
"""
OpForge ç¡¬ä»¶æŒ‡ä»¤ä¼˜åŒ–æ¼”ç¤º

å±•ç¤ºTritonã€ROCmä»¥åŠç¡¬ä»¶æŒ‡ä»¤ï¼ˆTensor Coreã€DOTæŒ‡ä»¤ç­‰ï¼‰æ”¯æŒã€‚
"""

import sys
from pathlib import Path

print("ğŸš€ OpForge - ç¡¬ä»¶æŒ‡ä»¤ä¼˜åŒ–æ¼”ç¤º")
print("=" * 60)
print()

# æ£€æŸ¥ä¾èµ–
try:
    from opforge.core import Backend, DataType, TensorShape, BackendManager
    from opforge.core.operator_base import HardwareInstruction, HardwareConfig
    from opforge.operators import Conv2DOperator
    from opforge.operators.conv_operator import Conv2DConfig
    from opforge.core.code_generator import CodeGenerator
    
    print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

print()

# 1. å±•ç¤ºæ‰©å±•çš„åç«¯æ”¯æŒ
print("ğŸ“‹ ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥æ‰©å±•çš„åç«¯æ”¯æŒ")
print("-" * 50)

manager = BackendManager()
backends = manager.get_available_backends()

print("ğŸ†• æ–°å¢åç«¯æ”¯æŒ:")
for backend in backends:
    capability = manager.get_backend_capability(backend)
    print(f"  â€¢ {backend.value}: {capability.name} v{capability.version}")
    
    features = []
    if capability.supports_fp16:
        features.append("FP16")
    if capability.supports_int8:
        features.append("INT8")
    if capability.compute_capability:
        features.append(f"Compute {capability.compute_capability}")
        
    if features:
        print(f"    ç‰¹æ€§: {', '.join(features)}")

print()
print("ğŸ¯ æ”¯æŒçš„ç¡¬ä»¶æŒ‡ä»¤:")
for instruction in HardwareInstruction:
    instruction_desc = {
        HardwareInstruction.TENSOR_CORE: "Tensor Core - NVIDIA GPUæ··åˆç²¾åº¦çŸ©é˜µè¿ç®—",
        HardwareInstruction.WMMA: "Warp Matrix Multiply Accumulate - çº¿ç¨‹æŸçŸ©é˜µè¿ç®—",
        HardwareInstruction.DOT2: "2å…ƒç´ ç‚¹ç§¯æŒ‡ä»¤",
        HardwareInstruction.DOT4: "4å…ƒç´ ç‚¹ç§¯æŒ‡ä»¤", 
        HardwareInstruction.DP4A: "4x8bitç‚¹ç§¯ç´¯åŠ æŒ‡ä»¤",
        HardwareInstruction.BUFFER_LOAD: "ç¼“å†²åŒºåŠ è½½æŒ‡ä»¤",
        HardwareInstruction.BUFFER_STORE: "ç¼“å†²åŒºå­˜å‚¨æŒ‡ä»¤",
        HardwareInstruction.MFMA: "Matrix Fused Multiply Add - AMD GPUæŒ‡ä»¤",
        HardwareInstruction.SHUFFLE: "Warp shuffleæŒ‡ä»¤",
        HardwareInstruction.REDUCE: "å½’çº¦æŒ‡ä»¤"
    }.get(instruction, instruction.value)
    
    print(f"  ğŸ”§ {instruction.value}: {instruction_desc}")

print()

# 2. æ¼”ç¤ºTensor Coreä¼˜åŒ–çš„å·ç§¯
print("ğŸ“‹ ç¬¬äºŒæ­¥ï¼šTensor Coreä¼˜åŒ–å·ç§¯æ¼”ç¤º") 
print("-" * 50)

# åˆ›å»ºç¡¬ä»¶é…ç½®
hardware_config = HardwareConfig()
hardware_config.supported_instructions.add(HardwareInstruction.TENSOR_CORE)
hardware_config.tensor_core_shapes = [(16, 16, 16)]
hardware_config.tensor_core_dtypes = {DataType.FLOAT16}

conv_config = Conv2DConfig(
    name="tensor_core_conv2d",
    backend=Backend.CUDA,
    dtype=DataType.FLOAT16,  # Tensor Coreéœ€è¦float16
    optimization_level=2,
    hardware_config=hardware_config,
    enable_tensor_core=True,
    enable_dot_instructions=True,
    in_channels=64,
    out_channels=128,
    kernel_size=3,
    stride=1,
    padding=1
)

print(f"âœ… åˆ›å»ºTensor Coreä¼˜åŒ–çš„å·ç§¯ç®—å­")
print(f"ğŸ“ çŸ©é˜µå½¢çŠ¶: {hardware_config.tensor_core_shapes[0]}")
print(f"ğŸ”¢ æ•°æ®ç±»å‹: {conv_config.dtype.value}")
print(f"âš¡ å¯ç”¨æŒ‡ä»¤: {', '.join([inst.value for inst in hardware_config.supported_instructions])}")

conv_operator = Conv2DOperator(conv_config)

# è®¾ç½®è¾“å…¥å½¢çŠ¶
input_shape = TensorShape(
    dims=[8, 64, 512, 512],  # å¤§å°ºå¯¸ä»¥å±•ç¤ºå†…å­˜ä¼˜åŒ–
    dtype=DataType.FLOAT16,
    name="tensor_input"
)

conv_operator.set_input_shapes([input_shape])
print(f"ğŸ“Š è¾“å…¥å½¢çŠ¶: {input_shape}")
print(f"ğŸ“Š è¾“å‡ºå½¢çŠ¶: {conv_operator.output_shapes[0]}")

# å†…å­˜åˆ†æ
memory_req = conv_operator.get_memory_requirements()
print(f"ğŸ’¾ å†…å­˜éœ€æ±‚: {memory_req['total_memory_bytes'] / 1024 / 1024:.2f} MB")

print()

# 3. æ¼”ç¤ºDOTæŒ‡ä»¤ä¼˜åŒ–
print("ğŸ“‹ ç¬¬ä¸‰æ­¥ï¼šDOTæŒ‡ä»¤ä¼˜åŒ–æ¼”ç¤º")
print("-" * 50)

# DOTæŒ‡ä»¤é…ç½®
dot_config = HardwareConfig()
dot_config.supported_instructions.update({
    HardwareInstruction.DOT2,
    HardwareInstruction.DOT4,
    HardwareInstruction.DP4A
})

print("ğŸ¯ DOTæŒ‡ä»¤ä¼˜åŒ–ç‰¹æ€§:")
print("  â€¢ DOT2: 2å…ƒç´ ç‚¹ç§¯ï¼Œé€‚ç”¨äºé‡åŒ–æ¨ç†")
print("  â€¢ DOT4: 4å…ƒç´ ç‚¹ç§¯ï¼Œé«˜æ•ˆçš„ä½ç²¾åº¦è®¡ç®—") 
print("  â€¢ DP4A: 4x8bitç‚¹ç§¯ç´¯åŠ ï¼ŒINT8ä¼˜åŒ–")

print()

# 4. æ¼”ç¤ºå¤šåç«¯ä»£ç ç”Ÿæˆ
print("ğŸ“‹ ç¬¬å››æ­¥ï¼šå¤šåç«¯ä»£ç ç”Ÿæˆæ¼”ç¤º")
print("-" * 50)

backends_to_test = [Backend.CUDA, Backend.TRITON]
if Backend.ROCM in manager.get_available_backends():
    backends_to_test.append(Backend.ROCM)

for backend in backends_to_test:
    print(f"\nğŸ”¨ ç”Ÿæˆ {backend.value} åç«¯ä»£ç ...")
    
    # åˆ›å»ºé…ç½®
    test_config = Conv2DConfig(
        name=f"{backend.value}_optimized_conv2d",
        backend=backend,
        dtype=DataType.FLOAT16,
        optimization_level=2,
        enable_tensor_core=(backend in [Backend.CUDA, Backend.TRITON]),
        enable_dot_instructions=(backend == Backend.CUDA),
        enable_buffer_ops=(backend in [Backend.ROCM]),
        in_channels=32,
        out_channels=64,
        kernel_size=3
    )
    
    test_operator = Conv2DOperator(test_config)
    test_input = TensorShape(
        dims=[4, 32, 256, 256],
        dtype=DataType.FLOAT16,
        name="test_input"
    )
    test_operator.set_input_shapes([test_input])
    
    try:
        # ç”Ÿæˆå‰å‘ä»£ç 
        forward_code = test_operator.generate_forward_code()
        if forward_code and len(forward_code) > 100:
            print(f"  âœ… {backend.value} å‰å‘ä»£ç ç”ŸæˆæˆåŠŸ ({len(forward_code)} å­—ç¬¦)")
            
            # å±•ç¤ºç‰¹å®šä¼˜åŒ–
            if backend == Backend.CUDA and "tensor" in forward_code.lower():
                print(f"    ğŸ¯ æ£€æµ‹åˆ°Tensor Coreä¼˜åŒ–")
            if backend == Backend.TRITON and "triton" in forward_code.lower():
                print(f"    ğŸ¯ æ£€æµ‹åˆ°Triton JITä¼˜åŒ–")
            if backend == Backend.ROCM and "mfma" in forward_code.lower():
                print(f"    ğŸ¯ æ£€æµ‹åˆ°MFMAæŒ‡ä»¤ä¼˜åŒ–")
        else:
            print(f"  âš ï¸  {backend.value} ä»£ç ç”Ÿæˆä¸ºç©º")
            
    except Exception as e:
        print(f"  âŒ {backend.value} ä»£ç ç”Ÿæˆå¤±è´¥: {e}")

print()

# 5. æ€§èƒ½å¯¹æ¯”åˆ†æ
print("ğŸ“‹ ç¬¬äº”æ­¥ï¼šæ€§èƒ½ä¼˜åŒ–åˆ†æ")
print("-" * 50)

optimization_levels = [
    ("æ— ä¼˜åŒ–", 0, "åŸºç¡€å®ç°ï¼Œä¾¿äºè°ƒè¯•"),
    ("åŸºç¡€ä¼˜åŒ–", 1, "å…±äº«å†…å­˜ã€å‘é‡åŒ–"),
    ("æ¿€è¿›ä¼˜åŒ–", 2, "Tensor Coreã€å¾ªç¯å±•å¼€ã€å¿«é€Ÿæ•°å­¦")
]

print("ğŸš€ ä¼˜åŒ–çº§åˆ«å¯¹æ¯”:")
for name, level, desc in optimization_levels:
    print(f"  â€¢ {name} (Level {level}): {desc}")

print()
print("ğŸ¯ ç¡¬ä»¶æŒ‡ä»¤æ€§èƒ½æå‡é¢„ä¼°:")
print("  â€¢ Tensor Core (FP16): ç†è®ºæå‡ 4-16x")
print("  â€¢ DOTæŒ‡ä»¤ (INT8): ç†è®ºæå‡ 2-4x") 
print("  â€¢ MFMA (ROCm): ç†è®ºæå‡ 8-16x")
print("  â€¢ ç¼“å†²åŒºä¼˜åŒ–: å‡å°‘å†…å­˜å»¶è¿Ÿ 20-30%")

print()

# 6. æ€»ç»“
print("ğŸ“‹ ç¬¬å…­æ­¥ï¼šåŠŸèƒ½æ€»ç»“")
print("-" * 50)

print("ğŸ‰ OpForge ç¡¬ä»¶æŒ‡ä»¤ä¼˜åŒ–åŠŸèƒ½å®Œæˆï¼")
print()
print("âœ¨ æ–°å¢åŠŸèƒ½:")
print("  â€¢ âœ… Tritonåç«¯æ”¯æŒ (Python JITç¼–è¯‘)")
print("  â€¢ âœ… ROCmåç«¯æ”¯æŒ (AMD GPU)")
print("  â€¢ âœ… Tensor CoreæŒ‡ä»¤æ”¯æŒ (16x16x16çŸ©é˜µ)")
print("  â€¢ âœ… DOTæŒ‡ä»¤æ”¯æŒ (dot2/dot4/dp4a)")
print("  â€¢ âœ… ç¼“å†²åŒºæ“ä½œä¼˜åŒ– (buffer_load/store)")
print("  â€¢ âœ… MFMAæŒ‡ä»¤æ”¯æŒ (AMD RDNAæ¶æ„)")
print("  â€¢ âœ… ç¡¬ä»¶æŒ‡ä»¤é…ç½®ç³»ç»Ÿ")
print("  â€¢ âœ… å¤šç²¾åº¦æ•°æ®ç±»å‹ä¼˜åŒ–")

print()
print("ğŸš€ ä½¿ç”¨æ–¹æ³•:")
print("  â€¢ æ ‡å‡†ç”Ÿæˆ: opforge generate-conv2d --backend cuda")
print("  â€¢ ç¡¬ä»¶ä¼˜åŒ–: opforge generate-hardware-optimized conv2d --enable-tensor-core")
print("  â€¢ Tritonä¼˜åŒ–: opforge generate-hardware-optimized conv2d --backend triton")
print("  â€¢ ROCmä¼˜åŒ–: opforge generate-hardware-optimized conv2d --backend rocm --enable-mfma")

print()
print("ğŸ“– æ”¯æŒçš„ç¡¬ä»¶æŒ‡ä»¤:")
print("  â€¢ NVIDIA: Tensor Core, WMMA, DOT2/4, DP4A, Shuffle")
print("  â€¢ AMD: MFMA, ç¼“å†²åŒºæ“ä½œ")
print("  â€¢ é€šç”¨: å‘é‡åŒ–ã€å¹¶è¡Œå½’çº¦")

print()
print("ğŸ¯ è¿™äº›åŠŸèƒ½è®©OpForgeèƒ½å¤Ÿ:")
print("  â€¢ ç”Ÿæˆé’ˆå¯¹ä¸åŒGPUæ¶æ„ä¼˜åŒ–çš„ä»£ç ")
print("  â€¢ å……åˆ†åˆ©ç”¨ç°ä»£GPUçš„ä¸“ç”¨è®¡ç®—å•å…ƒ")
print("  â€¢ æ”¯æŒæ··åˆç²¾åº¦å’Œé‡åŒ–æ¨ç†")
print("  â€¢ æä¾›å¯ç§»æ¤çš„é«˜æ€§èƒ½å®ç°")

if __name__ == "__main__":
    pass